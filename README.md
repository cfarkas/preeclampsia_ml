# preeclampsia_ml
Machine learning workflow for benchmarking classical machineâ€‘learning models on a maternalâ€“fetal dataset.

## ğŸš€Â Quickâ€‘start

```bash
# Oneâ€‘time: clone repository, create env and install dependences
git clone https://github.com/cfarkas/preeclampsia_ml.git
cd preeclampsia_ml
python3 main.py --install_conda

# Run the full pipeline
python3 main.py --input dataframe.csv --output ./out_20_80/
# Re-Train
python3 main.py --input ./out_20_80/subset_25.csv --output ./out_20_80/25_perc_subset/

# Run the full pipeline (using k-fold instead of split)
python3 main_kfold.py --input dataframe.csv --output ./out_10kfold/
# Re-Train (using k-fold instead of split)
python3 main_kfold.py --input ./out_10kfold/subset_25.csv --output ./out_10kfold/25_perc_subset/
```
```
# Cochran-Armitage trend test (exact, twoâ€‘sided) for ordinal variables
python3 cochran_armitage.py --csv dataframe.csv --meta_xlsx PE_dataset_variables.xlsx

# Exact Fisherâ€“Freemanâ€“Halton test for râ€¯Ã—â€¯c tables
python fisher_ffh.py --csv dataframe.csv --meta_xlsx PE_dataset_variables.xlsx
```
---

## Key Features

| Stage | Highlights |
|-------|------------|
| **Environment** | `--install_conda` bootstraps *ml_preeclampsia* env (PythonÂ 3.9Â +Â all deps). |
| **Reproducibility** | Global seed `SEEDÂ =Â 7` â†’ identical splits, weights and importances every run. |
| **Correlation analysis** | Generates both a **full Pearson matrix** *and* a **filtered matrix** that keeps any variable showing \|Ï\|Â â‰¥Â 0.12 with at least one outcome. |
| **Models** | **ClassificationÂ models:** `LogReg`, `LDA`, `GNB`, `KNN`, `DecTree`, `RF`, `GradBoost`, `SVM`, `MLP`.<br>**RegressionÂ models:** `RFreg`, `GBreg`. |
| **Metrics** | Macroâ€‘averaged **recall** (classification) &rarr; primary score.<br>MSEÂ /Â RMSEÂ /Â MAEÂ /Â RÂ² (regression). |
| **Visual reporting** | â€¢ **`pdfA_*.pdf`** confusionâ€‘matrix grids.<br>â€¢ **`pdfB_*.pdf`** permutationâ€‘importance bar grids.<br>â€¢ **`Fig3_paper.pdf`** consolidated bestâ€‘model bars (18â€¯Ã—â€¯14â€¯in).<br>â€¢ **`importances.pdf`** supersized dotâ€‘plot across *all* models/outcomes.<br>â€¢ **`Fig2_paper.pdf`** recall heatâ€‘map.<br>â€¢ **`Fig1_paper.pdf`** filtered correlation matrix. |
| **Feature export** | Three readyâ€‘toâ€‘use CSV subsets â€” importanceâ€¯>â€¯0.02, topâ€‘50â€¯%, topâ€‘25â€¯% â€” for reâ€‘training. | 

#### The subsets are obtained by the union of all predictors that fell within the top 25 % (or 50 %) permutation-importance ranks in the best-performing model for any outcome.

## Implementation Notes

- Scaling: numeric featuresÂ â†’Â StandardScaler; categoricalsÂ â†’Â labelâ€‘encoded.
- Permutation importance: 5 repeats, seeded, n_jobs=-1.
- Splits: 80â€¯/â€¯20 stratified (classification) or plain (regression), invoked with ```main.py```
- 10 K-fold cross validation, shuffling variables prior cross-validation, invoked with ```main_kfold.py```
---

## Outputs
```
results/
â”œâ”€â”€ Fig1_paper.pdf # filtered correlation (|Ï| â‰¥ 0.12, 30â€¯pt font)
â”œâ”€â”€ Fig2_paper.pdf # recall heatâ€‘map
â”œâ”€â”€ Fig3_paper.pdf # bestâ€‘model permutationâ€‘importances (panelsÂ Aâ€“F)
â”œâ”€â”€ importances.pdf # dotâ€‘plot: all models Ã— all outcomes
â”œâ”€â”€ pdfA_<outcome>.pdf # confusionâ€‘matrix grids
â”œâ”€â”€ pdfB_<outcome>.pdf # permutationâ€‘importance bar grids
â”œâ”€â”€ full_corr_matrix.pdf # complete Pearson matrix
â”œâ”€â”€ regression_metrics_summary.txt
â”œâ”€â”€ subset_overall_subset.csv
â”œâ”€â”€ subset_top50_percent.csv
â”œâ”€â”€ subset_top25_percent.csv
â””â”€â”€ â€¦ (additional PDFs for every outcome)
```
